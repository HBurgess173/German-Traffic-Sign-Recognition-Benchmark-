{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ecc35138-ec8a-4159-aeaa-c7a6153606f4",
   "metadata": {},
   "source": [
    "## Import Library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fafa9253-58f4-4a0a-833e-576424363001",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd \n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from PIL import Image\n",
    "import os\n",
    "import pathlib\n",
    "import random \n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator, img_to_array, array_to_img, load_img\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.models import Sequential, load_model\n",
    "from tensorflow.keras.applications import VGG19\n",
    "from tensorflow.keras.layers import Conv2D, MaxPool2D, Dense, Flatten, Dropout\n",
    "from sklearn.metrics import accuracy_score\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from keras.metrics import categorical_crossentropy\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
    "import itertools\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from PIL import Image\n",
    "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b5a9a3a-9658-4141-9e99-24c0e4cb115d",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.config.list_physical_devices('GPU')\n",
    "from tensorflow.python.client import device_lib\n",
    "print(device_lib.list_local_devices())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29babdd6-68cf-451f-9589-9a6057dca144",
   "metadata": {},
   "source": [
    "## Assign Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ce0d944-6bb4-4cce-a8de-40d96c2e7313",
   "metadata": {},
   "outputs": [],
   "source": [
    "# assign path for dataset\n",
    "data_dir ='C:/Users/hburg/OneDrive/Desktop/Data Science MSc/Machine Learning/ML Assignment/Data Set'\n",
    "train_path = data_dir + '/Train'\n",
    "test_path = data_dir + '/Test'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc6359cb-6569-4e83-83d6-b2b28612b04c",
   "metadata": {},
   "source": [
    "## Data Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a90a38d-0e7a-4e1b-aec0-e0e60e5466ca",
   "metadata": {},
   "source": [
    "\n",
    "### Load Data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0595cb5f-4165-44f9-a8aa-57f1ec1dbdf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Data\n",
    "train = pd.read_csv(train_path + '.csv')\n",
    "test = pd.read_csv(test_path + '.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2432b3f0-1eda-4d10-bf09-ee3539ca1ee7",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c863409d-084d-483b-8c50-4273edb37f9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# List the classes in the training directories\n",
    "train_classes = os.listdir(train_path)\n",
    "\n",
    "print(f\"Train Classes: {train_classes}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "590477e6-9fa5-4be3-ab89-ff48cda8c1d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# List all files in the test directory\n",
    "test_files = os.listdir(test_path)\n",
    "\n",
    "image_extensions = ('.jpg', '.jpeg', '.png', '.bmp', '.gif')\n",
    "test_images = [file for file in test_files if file.lower().endswith(image_extensions)]\n",
    "\n",
    "print(f\"Total number of images in the test set: {len(test_images)}\")\n",
    "print(f\"Test Images: {test_images[:10]}...\")  # Print the first 10 images as a sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12b388ad-0832-4ee6-95ac-006ab63a4811",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check the shape of the train and test dataset\n",
    "print(f\"Train dataset shape: {train.shape}\")\n",
    "print(f\"Test dataset shape: {test.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8a68e02-e5ca-4f6e-91c0-0317610b5411",
   "metadata": {},
   "outputs": [],
   "source": [
    "# List all subfolders (classes) in the training directory\n",
    "train_classes = os.listdir(train_path)\n",
    "\n",
    "# Define image extensions to check\n",
    "image_extensions = ['.jpg', '.jpeg', '.png', '.bmp', '.gif']\n",
    "\n",
    "\n",
    "image_counts_by_class = {cls: {ext: 0 for ext in image_extensions} for cls in train_classes}\n",
    "\n",
    "# Count the number of images for each extension in each class\n",
    "for cls in train_classes:\n",
    "    class_path = os.path.join(train_path, cls)\n",
    "    for file in os.listdir(class_path):\n",
    "        for ext in image_extensions:\n",
    "            if file.lower().endswith(ext):\n",
    "                image_counts_by_class[cls][ext] += 1\n",
    "\n",
    "# Calculate the total number of images for each class and for all classes\n",
    "total_images_by_class = {cls: sum(counts.values()) for cls, counts in image_counts_by_class.items()}\n",
    "total_images = sum(total_images_by_class.values())\n",
    "\n",
    "# Print the results for each class\n",
    "print(\"Image Counts by Type for Each Class:\")\n",
    "for cls, counts in image_counts_by_class.items():\n",
    "    print(f\"Class: {cls}\")\n",
    "    for ext, count in counts.items():\n",
    "        print(f\"  {ext}: {count} images\")\n",
    "    print(f\"  Total images in class '{cls}': {total_images_by_class[cls]}\")\n",
    "    print()\n",
    "\n",
    "# Print the overall total number of images\n",
    "print(f\"Total number of images in the training set: {total_images}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "856e1ed5-978e-47f1-b7cf-1c9cdb9fa97a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# List all files in the test directory\n",
    "test_files = os.listdir(test_path)\n",
    "\n",
    "image_extensions = ['.jpg', '.jpeg', '.png', '.bmp', '.gif']\n",
    "\n",
    "image_counts = {ext: 0 for ext in image_extensions}\n",
    "\n",
    "# Count the number of images for each extension\n",
    "for file in test_files:\n",
    "    for ext in image_extensions:\n",
    "        if file.lower().endswith(ext):\n",
    "            image_counts[ext] += 1\n",
    "\n",
    "# Calculate the total number of images\n",
    "total_images = sum(image_counts.values())\n",
    "\n",
    "# Print the results\n",
    "print(\"Image Counts by Type:\")\n",
    "for ext, count in image_counts.items():\n",
    "    print(f\"{ext}: {count} images\")\n",
    "\n",
    "print(f\"Total number of images in the test set: {total_images}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7af22327-76af-4484-915c-c70de569b335",
   "metadata": {},
   "outputs": [],
   "source": [
    "# find total class\n",
    "NUM_CATEGORIES = len(os.listdir(train_path))\n",
    "NUM_CATEGORIES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "633eac61-2fd5-4345-9421-3ba52343cee3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Visualise Sample Images in Training Data\n",
    "def plot_sample_images(directory, classes, n_samples=2):\n",
    "    for cls in classes:\n",
    "        image_path = os.path.join(directory, cls)\n",
    "        image_files = random.sample(os.listdir(image_path), n_samples)\n",
    "        fig, axes = plt.subplots(1, n_samples, figsize=(15, 5))\n",
    "        fig.suptitle(cls)\n",
    "        for ax, image_file in zip(axes, image_files):\n",
    "            img = Image.open(os.path.join(image_path, image_file))\n",
    "            ax.imshow(img)\n",
    "            ax.axis('off')\n",
    "        plt.show()\n",
    "\n",
    "plot_sample_images(train_path, train_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2638093-f9ff-442e-8e69-19a7873bf55d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Recursively gather all image file paths\n",
    "all_image_paths = []\n",
    "for root, dirs, files in os.walk(train_path):\n",
    "    for file in files:\n",
    "        if file.lower().endswith(('.png', '.jpg', '.jpeg', '.ppm')):\n",
    "            full_path = os.path.join(root, file)\n",
    "            all_image_paths.append(full_path)\n",
    "\n",
    "# Randomly sample 24 image paths\n",
    "sample_paths = random.sample(all_image_paths, 24)\n",
    "\n",
    "# Create 6Ã—4 grid\n",
    "fig, axes = plt.subplots(6, 4, figsize=(14, 12))\n",
    "fig.suptitle(\"Random Sample of GTSRB Images\", fontsize=16)\n",
    "\n",
    "for ax, img_path in zip(axes.ravel(), sample_paths):\n",
    "    img = Image.open(img_path)\n",
    "    class_id = os.path.basename(os.path.dirname(img_path))  # use folder name as class ID\n",
    "    ax.imshow(img)\n",
    "    ax.set_title(f\"Class {class_id}\", fontsize=8)\n",
    "    ax.axis('off')\n",
    "\n",
    "plt.tight_layout(rect=[0, 0.03, 1, 0.95])\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e0f5b3c-4500-469f-9de1-ed32eaeddd3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# List all classes in the train set\n",
    "train_classes = os.listdir(train_path)\n",
    "\n",
    "# Calculate the number of images in each class\n",
    "class_counts = {cls: len(os.listdir(os.path.join(train_path, cls))) for cls in train_classes}\n",
    "\n",
    "# Sort the classes numerically based on their class names\n",
    "sorted_class_counts = dict(sorted(class_counts.items(), key=lambda item: int(item[0])))\n",
    "\n",
    "# Visualise the class distribution\n",
    "class_counts_series = pd.Series(sorted_class_counts)\n",
    "plt.figure(figsize=(10, 6))\n",
    "class_counts_series.plot(kind='bar', color='blue')\n",
    "plt.title('Class Distribution in Training Set')\n",
    "plt.xlabel('Class')\n",
    "plt.ylabel('Number of Images')\n",
    "plt.xticks(rotation=45)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57a13143",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Number of classes to examine \n",
    "classes_to_plot = [0, 1, 11, 14, 22, 38]  \n",
    "\n",
    "# Plot pixel intensity histograms for selected classes\n",
    "for class_id in classes_to_plot:\n",
    "    class_dir = os.path.join(train_path, str(class_id))\n",
    "    if not os.path.isdir(class_dir):\n",
    "        continue\n",
    "\n",
    "    pixel_values = []\n",
    "\n",
    "    # Load and process images in the class directory\n",
    "    for img_name in os.listdir(class_dir)[:50]:  # Limit to 50 images per class for speed\n",
    "        img_path = os.path.join(class_dir, img_name)\n",
    "        try:\n",
    "            img = Image.open(img_path).convert('L')  # Convert to grayscale\n",
    "            pixel_array = np.array(img).flatten()\n",
    "            pixel_values.extend(pixel_array)\n",
    "        except Exception as e:\n",
    "            print(f\"Error loading {img_name}: {e}\")\n",
    "\n",
    "    # Plot histogram\n",
    "    plt.figure(figsize=(8, 4))\n",
    "    plt.hist(pixel_values, bins=30, color='gray', alpha=0.8, edgecolor='black')\n",
    "    plt.title(f\"Pixel Intensity Distribution - Class {class_id}\")\n",
    "    plt.xlabel(\"Pixel Intensity (0 = Black, 255 = White)\")\n",
    "    plt.ylabel(\"Frequency\")\n",
    "    plt.grid(True, linestyle='--', alpha=0.5)\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8693ddc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print example images for related histograms \n",
    "train_path = r'C:\\Users\\hburg\\OneDrive\\Desktop\\Data Science MSc\\Machine Learning\\ML Assignment\\Data Set\\Train'\n",
    "selected_classes = [0, 1, 14, 22, 11, 38]\n",
    "\n",
    "class_labels = {\n",
    "    0: \"Speed Limit 20\",\n",
    "    1: \"Speed Limit 30\",\n",
    "    14: \"Stop\",\n",
    "    22: \"Bumpy Road\",\n",
    "    11: \"Right-of-Way\",\n",
    "    38: \"Keep Right\"\n",
    "}\n",
    "\n",
    "# Create a 2Ã—3 grid plot\n",
    "fig, axes = plt.subplots(3, 2, figsize=(12, 8))\n",
    "fig.suptitle(\"Example Images from Selected Traffic Sign Classes\", fontsize=16)\n",
    "\n",
    "for ax, class_id in zip(axes.ravel(), selected_classes):\n",
    "    class_dir = os.path.join(train_path, str(class_id))\n",
    "    image_file = random.choice(os.listdir(class_dir))  \n",
    "    image_path = os.path.join(class_dir, image_file)\n",
    "\n",
    "    img = Image.open(image_path)\n",
    "    ax.imshow(img)\n",
    "    ax.set_title(f\"Class {class_id}: {class_labels[class_id]}\", fontsize=10)\n",
    "    ax.axis('off')\n",
    "\n",
    "plt.tight_layout(rect=[0, 0.03, 1, 0.95]) \n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d68121b4-ad23-48d8-8365-d2b14dba1cc1",
   "metadata": {},
   "source": [
    "## Label Overview"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "366d4112-fd79-4172-a2fe-61a978205c0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define a dictionary classes that maps class IDs to their corresponding traffic sign labels\n",
    "classes_labels = { \n",
    "            0:'Speed limit (20km/h)',\n",
    "            1:'Speed limit (30km/h)', \n",
    "            2:'Speed limit (50km/h)', \n",
    "            3:'Speed limit (60km/h)', \n",
    "            4:'Speed limit (70km/h)', \n",
    "            5:'Speed limit (80km/h)', \n",
    "            6:'End of speed limit (80km/h)', \n",
    "            7:'Speed limit (100km/h)', \n",
    "            8:'Speed limit (120km/h)', \n",
    "            9:'No passing', \n",
    "            10:'No passing veh over 3.5 tons', \n",
    "            11:'Right-of-way at intersection', \n",
    "            12:'Priority road', \n",
    "            13:'Yield', \n",
    "            14:'Stop', \n",
    "            15:'No vehicles', \n",
    "            16:'Veh > 3.5 tons prohibited', \n",
    "            17:'No entry', \n",
    "            18:'General caution', \n",
    "            19:'Dangerous curve left', \n",
    "            20:'Dangerous curve right', \n",
    "            21:'Double curve', \n",
    "            22:'Bumpy road', \n",
    "            23:'Slippery road', \n",
    "            24:'Road narrows on the right', \n",
    "            25:'Road work', \n",
    "            26:'Traffic signals', \n",
    "            27:'Pedestrians', \n",
    "            28:'Children crossing', \n",
    "            29:'Bicycles crossing', \n",
    "            30:'Beware of ice/snow',\n",
    "            31:'Wild animals crossing', \n",
    "            32:'End speed + passing limits', \n",
    "            33:'Turn right ahead', \n",
    "            34:'Turn left ahead', \n",
    "            35:'Ahead only', \n",
    "            36:'Go straight or right', \n",
    "            37:'Go straight or left', \n",
    "            38:'Keep right', \n",
    "            39:'Keep left', \n",
    "            40:'Roundabout mandatory', \n",
    "            41:'End of no passing', \n",
    "            42:'End no passing veh > 3.5 tons' }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "760acec5-e235-4a49-b377-5315c8ab5cda",
   "metadata": {},
   "source": [
    "## Data Pre-Processing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5dfa67d-75dc-49a0-90c6-82b22a9e4611",
   "metadata": {},
   "source": [
    "### Check For Missing Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d9ff132-58b4-4b24-b867-1644a8cd5415",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check train data\n",
    "train.isnull().any().describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6381f34e-b37c-423f-a26e-87dda34ddf63",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check test data\n",
    "test.isnull().any().describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae3e7ba1-6fe9-416e-bdb2-aad4cd24152a",
   "metadata": {},
   "source": [
    "### Check for Duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba4afb00-5ac1-455f-a1ef-244768e25a83",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check duplicates value\n",
    "print('Duplicate data in Train Set: ',train.duplicated().sum())\n",
    "print('Duplicate data in Test Set: ',test.duplicated().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "280ecbb5-ec71-4bcb-82b4-85740f0f2168",
   "metadata": {},
   "source": [
    "## Re-size Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65f30bdd-8913-4b62-b8b7-70761e67273d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "# Set image size\n",
    "IMG_HEIGHT = 96\n",
    "IMG_WIDTH = 96\n",
    "NUM_CATEGORIES = 43\n",
    "\n",
    "# Your train path\n",
    "train_path = 'C:/Users/hburg/OneDrive/Desktop/Data Science MSc/Machine Learning/ML Assignment/Data Set/Train'\n",
    "\n",
    "Collect image paths and labels\n",
    "image_paths = []\n",
    "image_labels = []\n",
    "\n",
    "for class_id in range(NUM_CATEGORIES):\n",
    "    class_folder = os.path.join(train_path, str(class_id))\n",
    "    for img_file in os.listdir(class_folder):\n",
    "        if img_file.endswith(('.png', '.jpg', '.jpeg')):\n",
    "            image_paths.append(os.path.join(class_folder, img_file))\n",
    "            image_labels.append(class_id)\n",
    "\n",
    "\n",
    "path_ds = tf.data.Dataset.from_tensor_slices((image_paths, image_labels))\n",
    "\n",
    "\n",
    "def process_image(file_path, label):\n",
    "    image = tf.io.read_file(file_path)\n",
    "    image = tf.image.decode_png(image, channels=3) \n",
    "    image = tf.image.resize(image, [IMG_HEIGHT, IMG_WIDTH])\n",
    "    image = tf.cast(image, tf.float32) / 255.0\n",
    "    return image, label\n",
    "\n",
    "\n",
    "dataset = path_ds.map(process_image, num_parallel_calls=tf.data.AUTOTUNE)\n",
    "\n",
    "\n",
    "image_data = []\n",
    "image_labels_np = []\n",
    "\n",
    "counter = 0\n",
    "for image, label in dataset:\n",
    "    image_data.append(image.numpy())\n",
    "    image_labels_np.append(label.numpy())\n",
    "    counter += 1\n",
    "    if counter % 100 == 0:\n",
    "        print(f\"âœ… Processed {counter} images...\")\n",
    "\n",
    "# Convert to NumPy arrays\n",
    "image_data = np.array(image_data)\n",
    "image_labels_np = np.array(image_labels_np)\n",
    "\n",
    "print(f\"\\nðŸŽ‰ Done! Processed a total of {counter} images.\")\n",
    "print(\"image_data.shape:\", image_data.shape)\n",
    "print(\"image_labels.shape:\", image_labels_np.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "636e74d6-8c86-4f1c-9364-067bdc88f50a",
   "metadata": {},
   "source": [
    "## Shuffle Training Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffd460c1-e771-4d3e-9b73-8c8f4049f513",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split  \n",
    "X = np.load(\"image_data\")\n",
    "y = np.load(\"image_labels.np\")\n",
    "\n",
    "# split data into train and validation set\n",
    "random_seed = 10\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    image_data, image_labels_np, test_size=0.3, random_state=random_seed, shuffle=True\n",
    ")\n",
    "\n",
    "print(X_train.shape, X_val.shape)\n",
    "print(y_train.shape, y_val.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b876890-d9fa-46e9-a5b4-6996ad48ce00",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "# Save arrays to .npy files\n",
    "np.save('X_train.npy', X_train)\n",
    "np.save('X_val.npy', X_val)\n",
    "np.save('y_train.npy', y_train)\n",
    "np.save('y_val.npy', y_val)\n",
    "\n",
    "print(\"âœ… Saved preprocessed training and validation data!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4581723-9615-4e0d-a635-9e757d79023d",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"X_train.shape\", X_train.shape)\n",
    "print(\"X_valid.shape\", X_val.shape)\n",
    "print(\"y_train.shape\", y_train.shape)\n",
    "print(\"y_valid.shape\", y_val.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c6ce6ba-bbac-4b1e-8ff0-9fa415efc25b",
   "metadata": {},
   "source": [
    "## Normalise Test and Train Data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "894e51f3-de1b-409c-87f1-011190149fd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train/255 \n",
    "X_val = X_val/255\n",
    "\n",
    "X_train\n",
    "X_val"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "865e945b-e43f-423d-a6ea-ea7fee3c2a23",
   "metadata": {},
   "source": [
    "## Label Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0fe1bda-1990-4e4a-894c-70c116ad0f86",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# One-hot encode the labels\n",
    "y_train = keras.utils.to_categorical(y_train, num_classes=NUM_CATEGORIES)\n",
    "y_val = keras.utils.to_categorical(y_val, num_classes=NUM_CATEGORIES)\n",
    "\n",
    "print(y_train.shape)\n",
    "print(y_val.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68311885-3ff6-401a-8057-1266370777a1",
   "metadata": {},
   "source": [
    "## Data Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd16056e-1f10-41e6-8f73-db0e63902078",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "epochs = 150"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05abaeb0-4c11-4034-b613-4e19b4f1f2ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "datagen = ImageDataGenerator(\n",
    "    rotation_range=20,\n",
    "    zoom_range=0.20,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    shear_range=0.2,\n",
    "    horizontal_flip=False,\n",
    "    vertical_flip=False,\n",
    "    fill_mode=\"nearest\"\n",
    ")\n",
    "\n",
    "datagen.fit(X_train)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5369a7d-d996-4f0c-a11d-fb092582e704",
   "metadata": {},
   "source": [
    "## Pre-Process Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ab2e5d5-395c-41f4-b3b8-dca472ad873c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "# Set image size \n",
    "IMG_HEIGHT = 96\n",
    "IMG_WIDTH = 96\n",
    "\n",
    "test_path = 'C:/Users/hburg/OneDrive/Desktop/Data Science MSc/Machine Learning/ML Assignment/Data Set/Test'\n",
    "\n",
    "\n",
    "test_image_paths = []\n",
    "\n",
    "for img_file in os.listdir(test_path):\n",
    "    if img_file.endswith(('.png', '.jpg', '.jpeg')):\n",
    "        test_image_paths.append(os.path.join(test_path, img_file))\n",
    "\n",
    "test_path_ds = tf.data.Dataset.from_tensor_slices(test_image_paths)\n",
    "\n",
    "\n",
    "def process_test_image(file_path):\n",
    "    image = tf.io.read_file(file_path)\n",
    "    image = tf.image.decode_png(image, channels=3)  \n",
    "    image = tf.image.resize(image, [IMG_HEIGHT, IMG_WIDTH])\n",
    "    image = tf.cast(image, tf.float32) / 255.0\n",
    "    return image\n",
    "\n",
    "\n",
    "test_dataset = test_path_ds.map(process_test_image, num_parallel_calls=tf.data.AUTOTUNE)\n",
    "\n",
    "\n",
    "X_test = []\n",
    "\n",
    "counter = 0\n",
    "for image in test_dataset:\n",
    "    X_test.append(image.numpy())\n",
    "    counter += 1\n",
    "    if counter % 100 == 0:\n",
    "        print(f\"âœ… Processed {counter} test images...\")\n",
    "\n",
    "X_test = np.array(X_test)\n",
    "np.save('X_test.npy', X_test)\n",
    "\n",
    "print(f\"\\nðŸŽ‰ Done! Processed a total of {counter} test images.\")\n",
    "print(\"X_test.shape:\", X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "702d031b-87e0-49ec-91ed-d3827be07278",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np3\n",
    "\n",
    "\n",
    "test_csv_path = 'C:/Users/hburg/OneDrive/Desktop/Data Science MSc/Machine Learning/ML Assignment/Data Set/Test.csv'\n",
    "\n",
    "test_df = pd.read_csv(test_csv_path)\n",
    "\n",
    "# Extract labels into NumPy array\n",
    "y_test = test_df['ClassId'].values\n",
    "\n",
    "# Check shape\n",
    "print(\"âœ… Loaded test labels only\")\n",
    "print(\"y_test shape:\", y_test.shape)\n",
    "print(\"Example labels:\", y_test[:10])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98ef53a0-feca-487b-80c5-218fc9cf326e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "random.seed(42)\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6eddfbb2-c12c-43a7-a9fa-a3bac6ac1215",
   "metadata": {},
   "source": [
    "## MobileNetv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "803f7e96-6f3c-45bb-8ddd-eb74fa3df2fd",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.applications import MobileNetV2\n",
    "from tensorflow.keras.applications.mobilenet_v2 import preprocess_input\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import GlobalAveragePooling2D, Dense, Dropout\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "X_train = np.load('X_train.npy')\n",
    "X_val = np.load('X_val.npy')\n",
    "y_train = np.load('y_train.npy')\n",
    "y_val = np.load('y_val.npy')\n",
    "X_test = np.load('X_test.npy')\n",
    "\n",
    "IMG_SIZE = 96\n",
    "\n",
    "mobilenet_base = MobileNetV2(input_shape=(IMG_SIZE, IMG_SIZE, 3), include_top=False, weights='imagenet')\n",
    "mobilenet_base.trainable = False\n",
    "\n",
    "model_mobilenet = Sequential([\n",
    "    mobilenet_base,\n",
    "    GlobalAveragePooling2D(),\n",
    "    Dense(128, activation='relu'),\n",
    "    Dropout(0.5),\n",
    "    Dense(43, activation='softmax')\n",
    "])\n",
    "\n",
    "model_mobilenet.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "early_stopping = EarlyStopping(monitor='val_accuracy', patience=5, restore_best_weights=True)\n",
    "\n",
    "history_mobilenet = model_mobilenet.fit(\n",
    "    X_train, y_train,\n",
    "    validation_data=(X_val, y_val),\n",
    "    epochs=30,\n",
    "    callbacks=[early_stopping]\n",
    ")\n",
    "\n",
    "model_mobilenet.save('mobilenet_model.h5')\n",
    "\n",
    "test_loss, test_accuracy = model_mobilenet.evaluate(X_test, y_test)\n",
    "\n",
    "print(\"MobileNetV2 Training Loss:\", history_mobilenet.history['loss'][-1])\n",
    "print(\"MobileNetV2 Training Accuracy:\", history_mobilenet.history['accuracy'][-1])\n",
    "print(\"MobileNetV2 Test Loss:\", test_loss)\n",
    "print(\"MobileNetV2 Test Accuracy:\", test_accuracy)\n",
    "\n",
    "plt.plot(history_mobilenet.history['loss'], label='train_loss')\n",
    "plt.plot(history_mobilenet.history['val_loss'], label='val_loss')\n",
    "plt.title('MobileNetV2 Loss')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "plt.plot(history_mobilenet.history['accuracy'], label='train_accuracy')\n",
    "plt.plot(history_mobilenet.history['val_accuracy'], label='val_accuracy')\n",
    "plt.title('MobileNetV2 Accuracy')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad48b72d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import (\n",
    "    classification_report,\n",
    "    confusion_matrix,\n",
    "    f1_score,\n",
    "    precision_score,\n",
    "    recall_score\n",
    ")\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.applications.mobilenet_v2 import preprocess_input\n",
    "\n",
    "# Load test data and model if not already in memory\n",
    "X_test = np.load('X_train.npy')\n",
    "y_test = np.load('y_train.npy')\n",
    "model_mobilenet = load_model('mobilenet_model.h5')\n",
    "\n",
    "# Preprocess for MobileNetV2\n",
    "X_test = preprocess_input(X_test)\n",
    "\n",
    "# Predict\n",
    "y_pred_probs = model_mobilenet.predict(X_test)\n",
    "y_pred_classes = np.argmax(y_pred_probs, axis=1)\n",
    "\n",
    "# Classification Accuracy\n",
    "accuracy = np.mean(y_pred_classes == y_test)\n",
    "print(f\"Classification Accuracy: {accuracy:.4f}\")\n",
    "\n",
    "# Precision, Recall, F1-Score\n",
    "precision = precision_score(y_test, y_pred_classes, average='weighted')\n",
    "recall = recall_score(y_test, y_pred_classes, average='weighted')\n",
    "f1_macro = f1_score(y_test, y_pred_classes, average='macro')\n",
    "f1_weighted = f1_score(y_test, y_pred_classes, average='weighted')\n",
    "\n",
    "print(f\"Precision (Weighted): {precision:.4f}\")\n",
    "print(f\"Recall (Weighted): {recall:.4f}\")\n",
    "print(f\"F1 Score (Macro): {f1_macro:.4f}\")\n",
    "print(f\"F1 Score (Weighted): {f1_weighted:.4f}\")\n",
    "\n",
    "# Confusion Matrix\n",
    "cm = confusion_matrix(y_test, y_pred_classes)\n",
    "plt.figure(figsize=(12, 10))\n",
    "sns.heatmap(cm, annot=False, fmt='d', cmap='Blues')\n",
    "plt.title('Confusion Matrix - MobileNetV2')\n",
    "plt.xlabel('Predicted Label')\n",
    "plt.ylabel('True Label')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Full classification report\n",
    "print(\"\\nDetailed Classification Report:\\n\")\n",
    "print(classification_report(y_test, y_pred_classes, digits=3))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a478d9d-88e9-449b-bfed-95ffc6e1209e",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## EfficientNetB0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bbcae56",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.applications import EfficientNetB0\n",
    "from tensorflow.keras.applications.efficientnet import preprocess_input\n",
    "\n",
    "X_train = np.load('X_train.npy')\n",
    "X_val = np.load('X_val.npy')\n",
    "y_train = np.load('y_train.npy')\n",
    "y_val = np.load('y_val.npy')\n",
    "X_test = np.load('X_test.npy')\n",
    "\n",
    "\n",
    "model_mobilenet.save('efficientNetb0_model.h5')\n",
    "\n",
    "test_loss, test_accuracy = model_efficientnet.evaluate(X_test, y_test)\n",
    "\n",
    "print(\"EfficientNetB0 Training Loss:\", history_efficientnet.history['loss'][-1])\n",
    "print(\"EfficientNetB0 Training Accuracy:\", history_efficientnet.history['accuracy'][-1])\n",
    "print(\"EfficientNetB0 Test Loss:\", test_loss)\n",
    "print(\"EfficientNetB0 Test Accuracy:\", test_accuracy)\n",
    "\n",
    "plt.plot(history_efficientnet.history['loss'], label='train_loss')\n",
    "plt.plot(history_efficientnet.history['val_loss'], label='val_loss')\n",
    "plt.title('EfficientNetB0 Loss')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "plt.plot(history_efficientnet.history['accuracy'], label='train_accuracy')\n",
    "plt.plot(history_efficientnet.history['val_accuracy'], label='val_accuracy')\n",
    "plt.title('EfficientNetB0 Accuracy')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
